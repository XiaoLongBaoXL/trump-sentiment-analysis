{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Donald Trump's tweets sentiment analysis and correlation with approval ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and API initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext lab_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style='whitegrid', palette='husl', font_scale=1.1, rc={\"figure.figsize\": [12, 8]})\n",
    "import numpy as np\n",
    "import datetime, json, logging, os, re\n",
    "import preprocessor as pre\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "from nltk import word_tokenize\n",
    "import spacy, en_core_web_sm\n",
    "nlp = en_core_web_sm.load()\n",
    "from collections import Counter\n",
    "from gensim.summarization import keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(filename='logfile.log', level=logging.DEBUG, \n",
    "                    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "\n",
    "name = 'realDonaldTrump'\n",
    "\n",
    "# dates range to collect tweets\n",
    "start_date = datetime.datetime(2018, 12, 18, 0, 0, 0)\n",
    "end_date = datetime.datetime(2019, 2, 19, 0, 0, 0)\n",
    "\n",
    "consumer_key = '5NTdgEYyu0ikbduFxjPJconG0'\n",
    "consumer_secret = 'RhoB2yyWl8L6mS3EmSEzCoMGlPsMX1z3XKQ0j2MXAagHwzU6yU'\n",
    "\n",
    "oauth_token = '4227898119-lQpkWMTn4mUPxNX9kPpoHbWlRJsmjsAzPwUHyZ8'\n",
    "oauth_token_secret = 'hp9Ga2IuDfPMGV2j56EfddLmaIrTP7BbgIWcurOXVaVY7'\n",
    "\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(oauth_token, oauth_token_secret)\n",
    "\n",
    "# the are rate limits for the frequency of API calls for twitter, \n",
    "# wait_on_rate_limit flag helps us not to worry about it while collecting the data\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True, wait_on_rate_limit_notify=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Andrei\n"
     ]
    }
   ],
   "source": [
    "print(api.me().name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tweets collection\n",
    "\n",
    "Now we collect the Trumps tweets from the specified date range. If already collected, read from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_tweets(tweets, file):\n",
    "    \"\"\"\n",
    "    collect all tweets for the specified account and time range,\n",
    "    save results to file\n",
    "    \n",
    "    \"\"\"\n",
    "    tweets_temp = api.user_timeline(\n",
    "        screen_name=name,\n",
    "        count=200,\n",
    "        include_rts='false',\n",
    "        tweet_mode='extended')\n",
    "    for tweet in tweets_temp:\n",
    "        if tweet.created_at < end_date and tweet.created_at > start_date:\n",
    "            tweets.append(tweet._json)\n",
    "\n",
    "    while (tweets_temp[-1].created_at > start_date):\n",
    "        tweets_temp = api.user_timeline(\n",
    "            screen_name=name,\n",
    "            count=200,\n",
    "            max_id=tweets_temp[-1].id,\n",
    "            include_rts='false',\n",
    "            tweet_mode='extended')\n",
    "        for tweet in tweets_temp:\n",
    "            if tweet.created_at < end_date and tweet.created_at > start_date:\n",
    "                tweets.append(tweet._json)\n",
    "\n",
    "    json.dump(tweets, file, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 24.3 ms, sys: 6.52 ms, total: 30.9 ms\n",
      "Wall time: 30.5 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if os.path.isfile('tweets.json') and not os.stat('tweets.json').st_size == 0:\n",
    "    logging.info('File tweets.json already exists! Reading the file..')\n",
    "    file = open('tweets.json', 'r', encoding='utf8')\n",
    "    tweets = json.load(file)\n",
    "    file.close()\n",
    "else:\n",
    "    logging.info('Creating tweets.json, collecting tweets..')\n",
    "    file = open('tweets.json', 'w', encoding='utf8')\n",
    "    tweets = []\n",
    "    collect_tweets(tweets, file)\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create dataframe to store and process the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I ask every member of the Maduro regime: End t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The people of Venezuela are standing for FREED...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>We are here to proclaim that a new day is comi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hope you are enjoying your President’s Day, ou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>“This was an illegal coup attempt on the Presi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Great analysis by @foxandfriends!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>....There is a lot of explaining to do to the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Wow, so many lies by now disgraced acting FBI ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>“After two years and interviewing more than tw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>William Barr is arriving at a Justice Departme...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text\n",
       "0  I ask every member of the Maduro regime: End t...\n",
       "1  The people of Venezuela are standing for FREED...\n",
       "2  We are here to proclaim that a new day is comi...\n",
       "3  Hope you are enjoying your President’s Day, ou...\n",
       "4  “This was an illegal coup attempt on the Presi...\n",
       "5                  Great analysis by @foxandfriends!\n",
       "6  ....There is a lot of explaining to do to the ...\n",
       "7  Wow, so many lies by now disgraced acting FBI ...\n",
       "8  “After two years and interviewing more than tw...\n",
       "9  William Barr is arriving at a Justice Departme..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(data=[tweet['full_text'] for tweet in tweets], columns=['Text'])\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what attributes available for each tweet object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id: 1097625026801688579\n",
      "date: Mon Feb 18 22:32:53 +0000 2019\n",
      "likes: 149000\n",
      "retweets: 41579\n",
      "{'hashtags': [], 'symbols': [], 'user_mentions': [], 'urls': []}\n"
     ]
    }
   ],
   "source": [
    "print('id:',tweets[0]['id'])\n",
    "print('date:',tweets[0]['created_at'])\n",
    "print('likes:',tweets[0]['favorite_count'])\n",
    "print('retweets:',tweets[0]['retweet_count'])\n",
    "print(tweets[0]['entities'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's add interesting attributes to the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>len</th>\n",
       "      <th>id</th>\n",
       "      <th>Date</th>\n",
       "      <th>Likes</th>\n",
       "      <th>RTs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I ask every member of the Maduro regime: End t...</td>\n",
       "      <td>268</td>\n",
       "      <td>1097625026801688579</td>\n",
       "      <td>Mon Feb 18 22:32:53 +0000 2019</td>\n",
       "      <td>149000</td>\n",
       "      <td>41579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The people of Venezuela are standing for FREED...</td>\n",
       "      <td>130</td>\n",
       "      <td>1097624329154674689</td>\n",
       "      <td>Mon Feb 18 22:30:07 +0000 2019</td>\n",
       "      <td>111651</td>\n",
       "      <td>31140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>We are here to proclaim that a new day is comi...</td>\n",
       "      <td>217</td>\n",
       "      <td>1097623506580357120</td>\n",
       "      <td>Mon Feb 18 22:26:51 +0000 2019</td>\n",
       "      <td>96212</td>\n",
       "      <td>30255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hope you are enjoying your President’s Day, ou...</td>\n",
       "      <td>89</td>\n",
       "      <td>1097592331405066242</td>\n",
       "      <td>Mon Feb 18 20:22:58 +0000 2019</td>\n",
       "      <td>155374</td>\n",
       "      <td>24288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>“This was an illegal coup attempt on the Presi...</td>\n",
       "      <td>110</td>\n",
       "      <td>1097488256848007173</td>\n",
       "      <td>Mon Feb 18 13:29:25 +0000 2019</td>\n",
       "      <td>115008</td>\n",
       "      <td>30164</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  len  \\\n",
       "0  I ask every member of the Maduro regime: End t...  268   \n",
       "1  The people of Venezuela are standing for FREED...  130   \n",
       "2  We are here to proclaim that a new day is comi...  217   \n",
       "3  Hope you are enjoying your President’s Day, ou...   89   \n",
       "4  “This was an illegal coup attempt on the Presi...  110   \n",
       "\n",
       "                    id                            Date   Likes    RTs  \n",
       "0  1097625026801688579  Mon Feb 18 22:32:53 +0000 2019  149000  41579  \n",
       "1  1097624329154674689  Mon Feb 18 22:30:07 +0000 2019  111651  31140  \n",
       "2  1097623506580357120  Mon Feb 18 22:26:51 +0000 2019   96212  30255  \n",
       "3  1097592331405066242  Mon Feb 18 20:22:58 +0000 2019  155374  24288  \n",
       "4  1097488256848007173  Mon Feb 18 13:29:25 +0000 2019  115008  30164  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['len'] = np.array([len(tweet['full_text']) for tweet in tweets])\n",
    "df['id'] = np.array([tweet['id'] for tweet in tweets])\n",
    "df['Date'] = np.array([tweet['created_at'] for tweet in tweets])\n",
    "df['Likes'] = np.array([tweet['favorite_count'] for tweet in tweets])\n",
    "df['RTs'] = np.array([tweet['retweet_count'] for tweet in tweets])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Fri Dec 21 03:13:54 +0000 2018', 'Wed Jan 30 21:58:38 +0000 2019')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(df.Date), max(df.Date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(533, 6)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Natural Language Processing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing\n",
    "\n",
    "Now lets do some preprocessing to prepare it for the entities extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove @user mentions, # hashtag symbol, URLs, emoji etc.\n",
    "# check the package documentation for info\n",
    "# pre.set_options(pre.OPT.URL, pre.OPT.EMOJI, pre.OPT.MENTION, pre.OPT.RESERVED, pre.OPT.SMILEY, pre.OPT.NUMBER)\n",
    "text_processed = df['Text'].apply(lambda s: pre.clean(s))\n",
    "\n",
    "# removing all non alpha-numeric symbols\n",
    "text_processed = text_processed.apply(lambda s: re.sub(r'[^A-Za-z0-9 ]', '', s))\n",
    "\n",
    "# removing stop words\n",
    "text_processed = text_processed.apply(lambda s: ' '.join(word for word in s.split() if word not in stop_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before:\n",
      "William Barr is arriving at a Justice Department that desperately needs an infusion of credibility, writes @KimStrassel https://t.co/naY9XOxb12 via @WSJ\n",
      "\n",
      "After:\n",
      "William Barr arriving Justice Department desperately needs infusion credibility writes via\n"
     ]
    }
   ],
   "source": [
    "print('Before:\\n' + df['Text'][9] + '\\n\\nAfter:\\n' + text_processed[9])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entities extraction\n",
    "Now after cleaning the data we can extract entities using SpaCy and NLTK and add it to the dataframe\n",
    "\n",
    "To see the transcription for the entities codes check the SpaCy documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_entities(text):\n",
    "    \"\"\"\n",
    "    Extract counts for each entity found in input text\n",
    "    \"\"\"\n",
    "    return dict(Counter([s.label_ for s in nlp(text).ents]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.42 s, sys: 45.3 ms, total: 8.47 s\n",
      "Wall time: 4.27 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "entities = text_processed.apply(lambda s: get_entities(s))\n",
    "entities = entities.apply(pd.Series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>len</th>\n",
       "      <th>id</th>\n",
       "      <th>Date</th>\n",
       "      <th>Likes</th>\n",
       "      <th>RTs</th>\n",
       "      <th>PERSON</th>\n",
       "      <th>ORG</th>\n",
       "      <th>CARDINAL</th>\n",
       "      <th>GPE</th>\n",
       "      <th>...</th>\n",
       "      <th>NORP</th>\n",
       "      <th>PRODUCT</th>\n",
       "      <th>MONEY</th>\n",
       "      <th>ORDINAL</th>\n",
       "      <th>TIME</th>\n",
       "      <th>LAW</th>\n",
       "      <th>EVENT</th>\n",
       "      <th>WORK_OF_ART</th>\n",
       "      <th>FAC</th>\n",
       "      <th>QUANTITY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I ask every member of the Maduro regime: End t...</td>\n",
       "      <td>268</td>\n",
       "      <td>1097625026801688579</td>\n",
       "      <td>Mon Feb 18 22:32:53 +0000 2019</td>\n",
       "      <td>149000</td>\n",
       "      <td>41579</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The people of Venezuela are standing for FREED...</td>\n",
       "      <td>130</td>\n",
       "      <td>1097624329154674689</td>\n",
       "      <td>Mon Feb 18 22:30:07 +0000 2019</td>\n",
       "      <td>111651</td>\n",
       "      <td>31140</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>We are here to proclaim that a new day is comi...</td>\n",
       "      <td>217</td>\n",
       "      <td>1097623506580357120</td>\n",
       "      <td>Mon Feb 18 22:26:51 +0000 2019</td>\n",
       "      <td>96212</td>\n",
       "      <td>30255</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hope you are enjoying your President’s Day, ou...</td>\n",
       "      <td>89</td>\n",
       "      <td>1097592331405066242</td>\n",
       "      <td>Mon Feb 18 20:22:58 +0000 2019</td>\n",
       "      <td>155374</td>\n",
       "      <td>24288</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>“This was an illegal coup attempt on the Presi...</td>\n",
       "      <td>110</td>\n",
       "      <td>1097488256848007173</td>\n",
       "      <td>Mon Feb 18 13:29:25 +0000 2019</td>\n",
       "      <td>115008</td>\n",
       "      <td>30164</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  len  \\\n",
       "0  I ask every member of the Maduro regime: End t...  268   \n",
       "1  The people of Venezuela are standing for FREED...  130   \n",
       "2  We are here to proclaim that a new day is comi...  217   \n",
       "3  Hope you are enjoying your President’s Day, ou...   89   \n",
       "4  “This was an illegal coup attempt on the Presi...  110   \n",
       "\n",
       "                    id                            Date   Likes    RTs  PERSON  \\\n",
       "0  1097625026801688579  Mon Feb 18 22:32:53 +0000 2019  149000  41579     1.0   \n",
       "1  1097624329154674689  Mon Feb 18 22:30:07 +0000 2019  111651  31140     NaN   \n",
       "2  1097623506580357120  Mon Feb 18 22:26:51 +0000 2019   96212  30255     NaN   \n",
       "3  1097592331405066242  Mon Feb 18 20:22:58 +0000 2019  155374  24288     NaN   \n",
       "4  1097488256848007173  Mon Feb 18 13:29:25 +0000 2019  115008  30164     2.0   \n",
       "\n",
       "   ORG  CARDINAL  GPE    ...     NORP  PRODUCT  MONEY  ORDINAL  TIME  LAW  \\\n",
       "0  1.0       1.0  1.0    ...      NaN      NaN    NaN      NaN   NaN  NaN   \n",
       "1  1.0       NaN  1.0    ...      NaN      NaN    NaN      NaN   NaN  NaN   \n",
       "2  NaN       NaN  1.0    ...      NaN      NaN    NaN      NaN   NaN  NaN   \n",
       "3  NaN       NaN  NaN    ...      NaN      NaN    NaN      NaN   NaN  NaN   \n",
       "4  NaN       NaN  NaN    ...      NaN      NaN    NaN      NaN   NaN  NaN   \n",
       "\n",
       "   EVENT  WORK_OF_ART  FAC  QUANTITY  \n",
       "0    NaN          NaN  NaN       NaN  \n",
       "1    NaN          NaN  NaN       NaN  \n",
       "2    NaN          NaN  NaN       NaN  \n",
       "3    NaN          NaN  NaN       NaN  \n",
       "4    NaN          NaN  NaN       NaN  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([df, entities], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collection of replies/comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now as we collected all Trump's tweets for the desired period, we can loop through them and actually collect people's reactions by getting the replies to these tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_replies(tweets, file):\n",
    "    \"\"\"\n",
    "    collect replies for all the collected tweets of the specified account,\n",
    "    query gets 100 replies per page, 10 pages give 1000 replies in total,\n",
    "    then compares with desired parameters,\n",
    "    finally saves results to file.\n",
    "    \n",
    "    \"\"\"\n",
    "    for tweet in tweets:\n",
    "        for page in tweepy.Cursor(\n",
    "            api.search,\n",
    "            # filter tweets by replies to @name and exclude retweets\n",
    "            q='to:' + name + ' -filter:retweets',\n",
    "            since_id=tweet['id'],\n",
    "            count=100,\n",
    "            # specifiy what type of search results you would prefer to receive. \n",
    "            # default is \"mixed\"\n",
    "            result_type='mixed',\n",
    "            tweet_mode='extended').pages(10):\n",
    "            for status in page:\n",
    "                if hasattr(status, 'in_reply_to_status_id_str'):\n",
    "                    logging.info('Found a reply to the tweet with id=',\n",
    "                                 status.in_reply_to_status_id_str,\n",
    "                                 'text=' + status.text)\n",
    "                    replies.append(status._json)\n",
    "                    logging.info('Reply added to the list. Continue...')\n",
    "    \n",
    "    json.dump(replies, file, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "if os.path.isfile('replies.json') and not os.stat('replies.json').st_size == 0:\n",
    "    logging.info('File replies.json already exists! Reading the file..')\n",
    "    file = open('replies.json', 'r', encoding='utf8')\n",
    "    replies = json.load(file)\n",
    "    file.close()\n",
    "else:\n",
    "    logging.info('Creating replies.json, collecting tweets..')\n",
    "    file = open('replies.json', 'w', encoding='utf8')\n",
    "    replies = []\n",
    "    collect_replies(tweets, file)\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll calculate the sentiment intensity for each of Trump's tweets using VADER which is especially tailored to work with social media texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "sentiment_intensity = df['Text'].apply(lambda s: analyzer.polarity_scores(s))\n",
    "df = pd.concat([df, sentiment_intensity.apply(pd.Series)], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets take a look at the distribution of positive/negative tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df['pos'])\n",
    "plt.xlabel('Positive intensity')\n",
    "plt.title('Trump\\'s positive tweets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df['neg'])\n",
    "plt.xlabel('Negative intensity')\n",
    "plt.title('Trump\\'s negative tweets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df['neu'])\n",
    "plt.xlabel('Neutral intensity')\n",
    "plt.title('Trump\\'s neutral tweets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df['compound'])\n",
    "plt.xlabel('Mixed intensity')\n",
    "plt.title('Trump\\'s mixed tweets')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
